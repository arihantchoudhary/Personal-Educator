{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(text):\n",
    "    speech = GPT().client.audio.speech.create(\n",
    "        model=\"tts-1\",\n",
    "        voice=\"onyx\",\n",
    "        input=text\n",
    "    )\n",
    "    return speech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech_mp3(text, filename):\n",
    "    speech = text_to_speech(text)\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(speech.content)\n",
    "\n",
    "text_to_speech_mp3(\"Hello World\", \"hello_world.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import io\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-page OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_pdf = open(\"llm-reasoning.pdf\", \"rb\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LLM Reasoning: \\nKey Ideas and Limitations \\nDenny Zhou \\n2024     CalTech   UC Berkeley   UPenn Google DeepMind  \\n', 'What do you expect for AI? \\nSolve the hardest math problems that humans \\ncannot solve? \\nDiscover new scientific theory? \\nSolve AGI? \\n…', 'My little expectation for AI \\nAI should be able to learn from just \\na few examples , like what humans \\nusually do ', 'Does ML meet this expectation? \\nSemi-supervised learning \\nBayesian nonparametric \\nKernel machines \\nSparsity \\nLow rank \\nActive learning \\n…\\n', 'What is missing in ML? \\nReasoning \\nHumans can learn from just a few examples  \\nbecause humans can reason ', 'Let’s start from a toy problem \\n“Make things as simple as possible but no simpler” \\n— Albert Einstein ', 'Last Letter Concatenation \\nRule : Take the last letter of each word, and then concatenate them Input Output \\n“Elon Musk” “nk”\\n“Bill Gates” “ls”\\n“Barack Obama” ?', 'Solve it by ML? Tons of labeled data needed! \\nEncoder Decoder \\n“Bill Gates” “ls”\\nWould you still refer to ML as AI when it requires vast amounts of labeled data to learn \\nsuch a “simple” task? ', 'Let’s see how this problem can \\nbe solved by using large \\nlanguage models (LLMs)! ', 'LLM “AI is the” “future” What are Large Language Models (LLMs)? \\nLLM is a “transformer” model trained to predict the next word \\nEg “AI is the future”  \\nTrained with many sentences, e.g. all texts from the Internet ', 'You can think of training LLMs \\nas training parrots to mimic \\nhuman languages  ', 'Q: “Elon Musk” \\nA: “nk” \\nQ: “Bill Gates” \\nA: “ls” \\nQ: “Barack Obama” \\nA:LLM\\nInput Few-shot prompting for last-letter-concatenation  \\n“ck”', 'Let’s add “reasoning process” before “answer” \\nQ: “Elon Musk” \\nA: the last letter of \"Elon\" is \"n\". the last letter of \"Musk\" is \"k\". Concatenating \"n\", \"k\"  \\nleads to \"nk\". so the output is \"nk\". \\nQ: “Bill Gates” \\nA: the last letter of \"Bill\" is \"l\". the last letter of \"Gates\" is \"s\". Concatenating \"l\", \"s\" leads  \\nto \"ls\". so the output is \"ls\". \\nQ: “Barack Obama\" \\nA: reasoning process ', 'Let’s add “reasoning process” before “answer” \\nQ: “Elon Musk” \\nA: the last letter of \"Elon\" is \"n\". the last letter of \"Musk\" is \"k\". Concatenating \"n\", \"k\"  \\nleads to \"nk\". so the output is \"nk\". \\nQ: “Bill Gates” \\nA: the last letter of \"Bill\" is \"l\". the last letter of \"Gates\" is \"s\". Concatenating \"l\", \"s\" leads  \\nto \"ls\". so the output is \"ls\". \\nQ: “Barack Obama\" \\nA: the last letter of \"Barack\" is \"k\". the last letter of \"Obama\" is \"a\". Concatenating \"k\", \"a\"  \\nleads to \"ka\". so the output is \"ka\". reasoning process ', 'One demonstration is enough, like humans \\nQ: “Elon Musk” \\nA: the last letter of \"Elon\" is \"n\". the last letter of \"Musk\" is \"k\". Concatenating \"n\", \"k\"  \\nleads to \"nk\". so the output is \"nk\". \\nQ: “Barack Obama\" \\nA: the last letter of \"Barack\" is \"k\". the last letter of \"Obama\" is \"a\". Concatenating \"k\", \"a\"  \\nleads to \"ka\". so the output is \"ka\". \\n100% accuracy with only one demonstration example ', 'Key Idea: Derive the Final Answer through \\nIntermediate Steps \\nLing et al. Program Induction by Rationale  \\nGeneration: Learning to Solve and Explain  \\nAlgebraic Word Problems . ACL 2017 \\nLing et al 2017  in DeepMind pioneered using natural language rationale  to \\nsolve math problems by “... derive the final answer through a series of small \\nsteps ”. Trained a sequence-to-sequence model from scratch. \\n', 'GSM8K: <Problem, Intermediate Steps , Answer> \\nCobbe et al. Training \\nVerifiers to Solve Math Word \\nProblems.  arXiv:2110.14168  \\n[cs.LG]. 2021 Following the work by Ling et al 2017, Cobbe et al 2021 in OpenAI built a much \\nlarger math word problem dataset (GSM8K) with natural language rationales,  \\nand used it to finetune GPT3 \\nProblem:  Ali is a dean of a private school where he teaches one class. \\nJohn is also a dean of a public school. John has two classes in his \\nschool. Each class has 1/8 the capacity of Ali’s class which has the \\ncapacity of 120 students. What is the combined capacity of both schools? \\nSolution: Ali’s class has a capacity of 120 students. Each of John’s \\nclasses has a capacity of 120/8 = 15 students. The total capacity of \\nJohn’s two classes is 15 students * 2 classes = 30 students. The \\ncombined capacity of the two schools is 120 students + 30 students = \\n150 students. \\nFinal answer: 150 \\n', 'Show Your Work: Scratchpads for  Intermediate \\nComputation with Language Models\\nNye et al. Show Your Work: Scratchpads \\nfor Intermediate Computation with \\nLanguage Models. arXiv:2112.00114  \\n[cs.LG], 2021 \\n', 'Chain-of-Thought  (CoT) Prompting \\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and Denny  Zhou.  \\nChain-of-thought prompting elicits reasoning in large language models . NeurIPS 2022 ', 'Training with intermediate steps (Ling et al 2017) \\nFinetuning with intermediate steps (Cobbe et al 2021, Nye et al  2021) \\nPrompting with intermediate steps (Nye et al 2021, Wei et al 2022) \\nThis is what really matters! ', 'Regardless of training, fine-tuning, or \\nprompting, when provided with examples \\nthat include intermediate steps, LLMs will \\nrespond with intermediate steps ', 'Is it also helpful to add reasoning \\nstrategies in demonstration examples? ', 'Least-to-Most Prompting \\nEnable easy-to-hard generalization by decomposition \\nDenny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale \\nSchuurmans, Claire Cui, Olivier Bousquet, Quoc Le, Ed Chi. Least-to-Most Prompting  \\nEnables Complex Reasoning in Large Language Models . ICLR 2023. ', '', \"Elsa has 3 apples. Anna has 2 more apples than Elsa. How many \\napples do they have together? \\nLet's break down this problem: 1. How many apples does Anna \\nhave? 2. How many apples do Elsa and Anna have together? \\n1.Anna has 2 more apples than Elsa.  So Anna has 2 + 3 = 5 apples. \\n2.Anna has 5 apples. Elsa and Anna have 3 + 5 = 8 apples together. \\nThe answer is 8. \\n\", 'SCAN  (Compositional Generalization) \\nUsing just 0.1% demonstration examples  achieves perfect generalization ', 'CFQ (Compositional Generalization): Text-to-Code \\nAndrew Drozdov, Nathanael Schärli, Ekin Akyürek, Nathan Scales, Xinying Song, Xinyun Chen, Olivier \\nBousquet, Denny Zhou. Compositional Semantic Parsing with Large Language Models . ICLR 2023. Using just 1% data! \\n', 'Why intermediate steps are helpful? \\n“There is nothing more practical than a good theory.” \\n— Kurt Lewin ', 'Zhiyuan Li, Hong Liu, Denny Zhou, and Tengyu Ma. Chain of Thought Empowers  \\nTransformers to Solve Inherently Serial Problems . ICLR 2024. ●Constant-depth transformers can solve any inherently \\nserial problem as long as it generates sufficiently long \\nintermediate reasoning steps \\n●Transformers which directly generate final answers  \\neither requires a huge depth to solve or cannot solve at all ', 'Tons of practical implications of this theory \\nGenerating more intermediate steps (think longer) \\nToo long to generate? Calling external tools e.g. MCTS \\nDistill test-time search? You will need a huge depth! \\nWhich to choose:  transformer vs RNN/SSM \\n…', 'Is it possible to trigger step by step \\nreasoning without using \\ndemonstration examples? ', 'Let’s think \\nstep by step \\nKojima, T., Gu, S.S., Reid, M., Matsuo, Y.  \\nand Iwasawa, Y. Large language models  \\nare zero-shot reasoners. NeurIPS 2022. \\n', 'Hmm, zero-shot is cool but usually \\nsignificantly worse than few-shot … ', 'LLMs as Analogical Reasoners \\nMichihiro Yasunaga, Xinyun Chen, Yujia Li, Panupong Pasupat, Jure Leskovec, Percy Liang, \\nEd H. Chi, Denny Zhou. Large Language Models as Analogical Reasoners . ICLR 2024. ', '', '“A mathematician is a person who can find analogies  \\nbetween theorems; a better mathematician is one who can  \\nsee analogies between proofs and the best mathematician  \\ncan notice analogies between theories. One can imagine  \\nthat the ultimate mathematician is one who can see  \\nanalogies between analogies .”\\n \\n— Stefan Banach ', \"What is the area of the square with the four vertices at (-2, 2), (2, -2), (-2, -6), and (-6, \\n-2)?  Recall a related problem, and then solve this one.  \\nThe related problem is finding the distance between two points on a coordinate \\nplane . To find the distance between two points, we use the distance formula: d = √\\n((x2-x1)^2 + (y2-y1)^2). \\nIn this problem, we have four points: (-2, 2), (2, -2), (-2, -6), and (-6, -2). Let's choose (-2, 2) \\nand (2, -2) to find the distance d between them: d = √((2-(-2))^2 + (-2-2)^2)  = √(4^2 + \\n(-4)^2)  = √(16 + 16)  = √32. We know that the distance between two opposite sides of a \\nsquare is equal. So, the length of each side of the square is √32. To find the area of the \\nsquare, we square the length of one side: Area = (√32)^2 = 32. \", 'Analogical reasoner vs zero-shot / few-shot CoT ', 'Analogical reasoner vs zero-shot / few-shot CoT \\n', 'Analogical reasoner vs zero-shot / few-shot CoT \\n', 'Analogical reasoning:  \\nadaptively generate relevant \\nexamples and knowledge, \\nrather than just using a fix set of \\nexamples  \\n', 'Is it possible to trigger step by step \\nreasoning even without using any \\nprompt like “let’s think step by step”? ', 'Chain-of-Thought Reasoning \\nwithout Prompting \\nXuezhi Wang and Denny Zhou.  Chain-of-Thought Reasoning Without Prompting . \\narXiv preprint arXiv:2402.10200 (2024). ', 'Top-1: Nicolas Nicolas  Cage was born in an odd year. \\nTop-2: Even Even .\\nTop-3: Odd Odd.\\nTop-4: 1964 1964 , an even year. \\nTop-5: He He was born in an even year. \\nTop-6: Cage Cage  was born in 1964, an even year. Was Nicolas Cage born in an even or odd year? Chain-of-Thought Decoding ', '1 Nicolas Cage was born in an odd year.    0.117 \\n2 Even . 0.207 \\n3 Odd. 0.198 \\n4 1964, an even  year. 0.949 \\n5 He was born in an even  year. 0.000 \\n6 Cage was born in 1964, an even year. 0.978 Probability for the answer token ', 'Top-1: 5 5 apples. \\nTop-2: I I have 3 apples, my dad has 2 more apples than me, \\nso he has 5 apples. 3+5=8. \\nTop-3: We We have 8 apples in total. \\nTop-4: You You have 3 apples, your dad has 2 more apples than \\nyou, so he has 5 apples. 3+5=8. \\nTop-5: The The answer is 5. I have 3 apples, my dad has 2 more apples than me, how many apples do we \\nhave in total? ', '1.Pre-trained LLMs, without further finetuning, has \\nbeen ready for step-by-step reasoning, but we \\nneed a non-greedy decoding strategy to elicit it  \\n2.When a step-by-step reasoning path is present, \\nLLMs have much higher confidence in decoding \\nthe final answer than direct-answer decoding Key takeaways ', 'Greedy Decoding vs Chain-of-Thought Decoding \\n', 'Generating intermediate steps \\nare helpful, but … ', 'Any concern on generating intermediate \\nsteps instead of direct answers? \\nAlways keep in mind that LLMs are probabilistic models \\nof generating next tokens.  They are not humans. \\n', 'What LLM does in decoding :\\nWhat we want :\\nNot \\nalign! \\n', 'One-step further \\nHow to compute the sum then? Sampling! ', 'Self-Consistency \\nGreatly improves step-by-step reasoning \\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou. \\nSelf-Consistency Improves Chain of Thought Reasoning in Language Models . ICLR 2023. ', '[Question]  Janet’s ducks lay 16 eggs per day. She eats three for breakfast \\nevery morning and bakes muffins for her friends every day with four. She \\nsells the remainder for $2 per egg. How much does she make every day? \\nResponse 1:  She has 16 - 3 - 4 = 9 eggs left. So she makes $2 * 9 = $ 18 per day. Sampled responses: \\nResponse 2 : This means she she sells the remainder for $2 * (16 - 4 - 3) = $ 26 per day. \\nResponse 3 : She eats 3 for breakfast, so she has 16 - 3 = 13 left. Then she bakes \\nmuffins, so she has 13 - 4 = 9 eggs left. So she has 9 eggs * $2 = $ 18.\\nMost frequent answer is: 18 \\n(Not most frequent reasoning path!) \\n', 'Crushed GSM8K SOTA with only 8 examples \\n', 'More consistent, more likely to be correct \\n', '[Q1] When the LLM outputs a direct answer without intermediate \\nsteps, will you still sample several times, and then choose the \\nmost common answer? \\n[Q2] Change self-consistency by letting LLM generate multiple \\nresponses, instead of sampling multiple times, and then choosing \\nthe most common answer. Does this make sense? \\n', 'How about free-from answers? \\nUniversal Self-Consistency (USC) \\nAsk LLMs to self-select the most consistent answer \\nXinyun Chen, Renat Aksitov, Uri Alon, Jie Ren, Kefan Xiao, Pengcheng Yin, Sushant Prakash, Charles Sutton, Xuezhi Wang, Denny Zhou. \\nUniversal Self-Consistency for Large Language Model Generation . arXiv:2311.17311 [cs.CL], 2023. ', '[Question]  Where do people drink less coffee than they do in Mexico? \\nResponse 1 : ... Some examples include Japan, China and the United Kingdom. \\nIt is important to note that coffee consumption can vary among individuals within these \\ncountries, and preferences can change depending on different factors such as… \\nResponse 2 : People in countries like Japan, China, and India typically drink less coffee \\nthan they do in Mexico... \\nResponse 3 : There are several countries where people generally drink less coffee \\ncompared to Mexico. Some of these countries include: \\n1. Japan:... \\n2. China... \\n3. Saudi Arabia... \\n4. India... \\n...The most consistent response: 2 ', 'Limitations ', 'LLMs Can Be Easily Distracted \\nby Irrelevant Context \\nFreda Shi, Xinyun Chen, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael Schärli, and Denny Zhou.  Large  \\nLanguage Models Can Be Easily Distracted by Irrelevant Context.   ICML 2023 .', 'Humans may be easily distracted by irrelevant context \\nPsychology studies show that irrelevant information may significantly \\ndecrease some children and even adults problem-solving accuracy \\n… inattentive children’s difficulties in problem solving are partially \\ndue to an inability to inhibit irrelevant information … \\nMarzocchi, G.M., Lucangeli, D., De Meo, T., Fini, F. and Cornoldi, C., 2002. The disturbing  \\neffect of irrelevant information on arithmetic problem solving in inattentive children.  \\nDevelopmental neuropsychology , 21(1), pp.73-92. Does this observation \\nhold for LLMs? ', \"[Prompt] Lucy has $65 in the bank. She made a $15 deposit and then \\nfollowed by a $4 withdrawal. Maria's monthly rent is $10. What is Lucy’s \\nbank balance?  \\n[Response] Lucy's bank balance is $65 + $15 - $4 - $10  = $66. The \\nanswer is $66. Adding irrelevant contexts to GSM8K leads to 20+ \\npoints performance drop  \", \"[Prompt] Lucy has $65 in the bank. She made a $15 deposit and then \\nfollowed by a $4 withdrawal. Maria's monthly rent is $10. What is Lucy’s \\nbank balance?  Ignore irrelevant context \\n[Response] Lucy has $65 in the bank. After making a $15 deposit and \\nthen a $4 withdrawal, her bank balance is $76. Maria's monthly rent is  \\nnot relevant to this question, so it can be ignored.  The answer is $76. \\nInstructing LLMs to Ignore irrelevant context  can \\ntake some performance back \", 'We can simply add many irrelevant sentences \\nThe sky is blue.  The sky is blue. The sky is blue. The sky is blue. Lucy has \\n$65 in the bank . … The sky is blue. The grass is green. The grass is green. \\nShe made a $15 deposit and then followed by a $4 withdrawal.  … The \\nsky is blue. The sky is blue. The sky is blue. The sky is blue. The grass is \\ngreen. The grass is green. The sky is blue.  The grass is green. … What is \\nLucy’s bank balance? ', 'LLMs Cannot Self-Correct \\nReasoning Yet \\nJie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, Denny Zhou. Large  \\nLanguage Models Cannot Self-Correct Reasoning Yet . ICLR 2024. ', \"Christina is planning a birthday party and needs .75 gift bags per invited guest, \\nbecause 1/4 of attendees don't show up. She invited 16 friends. Gift bags are $2 \\neach. How much will she spend? \\n... 0.75 * 12 = 9 gift bags … Christina will spend a total of 2 * 9 = $8 ... (Wrong) \\nReview your previous answer and find problems with your answer.  \\nUpon reviewing my previous answer, I recognize a mistake. I incorrectly stated \\nthat Christina needs 0.75 gift bags per invited guest. The given information \\nstates that 1/4 of the attendees won't show up… \\nBased on the problems you found, improve your answer. \\n... 16 * (3/4) = 12 gift bags … Christina will spend 12 * $2 = $24 … (Correct) \", \"Terry eats 2 yogurts a day. They are currently on sale at 4 yogurts for $5.00. How \\nmuch does he spend on yogurt over 30 days? \\n... So, Terry spends $75 on yogurt over 30 days. (Correct) \\nReview your previous answer and find problems with your answer.  \\nUpon reviewing my previous answer, I realized that I made a mistake in calculating \\nTerry's spending on yogurt over 30 days. I incorrectly stated that Terry spends \\n$2.50 per day for 30 days… \\nBased on the problems you found, improve your answer. \\n ... the final answer is Terry spends $37.5 on yogurt over 30 days. (Wrong) \", 'While allowing LLMs to review their generated \\nresponses can help correct inaccurate answers, \\nit may also risk changing correct answers into \\nincorrect ones ', 'Self-correcting results in worse results \\n', 'Reported improvements need oracle answers \\nOracle: Let LLMs self correct only when the answer is wrong ', 'Multi-LLM debate? Worse than self-consistency! \\n', 'Oracle feedback needed for LLM \\nto self-correct Lesson learned ', 'Self-debug naturally leverage unit tests as oracle \\nXinyun Chen, Maxwell Lin, Nathanael Schärli, Denny Zhou.  Teaching Large Language Models to Self-Debug .  \\narXiv:2302.00093 [cs.CL], 2023. ICLR 2024. \\n', 'Premise Order Matters in LLM \\nReasoning \\nXinyun Chen, Ryan A Chi, Xuezhi Wang, Denny Zhou.  Premise Order Matters in  \\nReasoning with Large Language Models . ICML 2024. ', '[Original GSM8K Problem] Thomas withdraws $1000 in 20 dollar bills \\nfrom the bank account. He loses 10 bills while getting home . After that, he \\nuses half of the remaining bills to pay for a bill. Thomas then triples his \\nmoney. He then converts all his bills to 5 dollar bills. How many 5 dollar \\nbills does he have? \\n[Reordered GSM8K Problem] Thomas withdraws $1000 in 20 dollar bills \\nfrom the bank account. After getting home , he uses half of the remaining \\nbills to pay for a bill. Thomas then triples his money. He then converts all \\nhis bills to 5 dollar bills. He loses 10 bills while getting home . How many 5 \\ndollar bills does he have? \\nAbout 10 points drop on solving rates across all frontier LLMs ', '1. Thomas withdraws $1000 in $20 \\nbills. $1000 / $20 = 50 bills \\n2. He loses 10 of those bills. 50 bills \\n- 10 bills = 40 bills \\n3. He uses half of the remaining \\nbills to pay for a bill. Half of 40 bills \\nis 20 bills. 40 bills - 20 bills = 20 \\nbills remaining \\n4. Thomas then triples his money. \\nHe has 20 bills of $20, which is 20 * \\n$20 = $400. Tripling $400 gives us \\n$400 * 3 =$1200. \\n5. He converts all his money to $5 \\nbills. $1200 / $5 = 240 bills \\n1. Thomas withdraws $1000 in $20 \\nbills from the bank. $1000 / $20 = \\n50 bills \\n2. He uses half of the remaining \\nbills to pay for a bill. Half of 50 bills \\nis 25 bills. So, he uses 25 bills and \\nhas 25 bills left. \\n3. Thomas then triples his money. \\nSince he had 25 bills of $20 each, \\nhe had 25 * $20 = $500 before \\ntripling his money. Tripling $500 \\ngives him $500 * 3 = $1500. \\n4. He then converts all his bills to \\n$5 bills. $1500 / $5 = 300 bills \\n5. He lost 10 bills while getting \\nhome. 300 bills - 10 bills = 290 bills Response for original Response for reordered ', 'Rules: If duve, then dax. If kere and riff, then tess. If feg and tess, then rabe. If wozz, then \\nriff. If rabe, then thoxe. If ag and riff and kere, then hepe. If thoxe, then vepe. If nife and hume \\nand ag, then dax. If feg and thoxe, then ire. If rebe and ene and heff, then kone. If ire and \\ndax, then wope. If tess and vepe, then nup. If rabe and vide and nife, then ag. If nup and ag \\nand vide, then duve. If zeck and hepe and dax, then riff. If nup, then hepe. If sene, then \\nhume. If hepe and tess and ag, then kere. If fum, then vide. If kere and wope, then fum. If jag \\nand kone, then thoxe. If fum, then wozz. \\nFacts: Alice is cote. Alice is kone. Alice is duve. Alice is ag. Alice is jag. Alice is tess. Alice is \\nriff. Alice is feg. Alice is vide. \\nQuery: Is Alice wozz? In each step, indicate whether you are using a fact, or a rule. \\nLogical inference task : The rules are ordered according to their use in the \\ninference process, though not all rules are necessary for the query ', 'Rules : If nup, then hepe. If kere and riff, then tess. If feg and tess, then rabe. If wozz, then \\nriff. If tess and vepe, then nup.If ag and riff and kere, then hepe. If feg and thoxe, then ire. If \\nnife and hume and ag, then dax. If ire and dax, then wope. If rebe and ene and heff, then \\nkone. If hepe and tess and ag, then kere. If rabe, then thoxe. If rabe and vide and nife, then \\nag. If fum, then wozz. If zeck and hepe and dax, then riff. If kere and wope, then fum. If sene, \\nthen hume. If thoxe, then vepe. If fum, then vide. If duve, then dax. If jag and kone, then \\nthoxe. If nup and ag and vide, then duve. \\nFacts : Alice is cote. Alice is kone. Alice is duve. Alice is ag. Alice is jag. Alice is tess. Alice is \\nriff. Alice is feg. Alice is vide. \\nQuery : Is Alice wozz? In each step, indicate whether you are using a fact, or a rule. \\nLogical inference task : The rules relevant to the query are randomly  ordered, \\n30+ points performance drop across all frontier LLMs ', 'Summary \\n●Generating intermediate steps improves LLM performance \\n○Training / finetuning / prompting with intermediate steps \\n○Zero-shot, analogical reasoning, special decoding \\n●Self-consistency greatly improves step-by-step reasoning \\n●Limitation: irrelevant context, self-correction, premise order ', 'What is next? \\nIf I were given one hour to save the planet, I would spend 59  minutes  \\ndefining the problem and one minute resolving it. \\n— Albert Einstein ', '1.Define a right problem to work on \\n2.Solve it from the first principles ', 'Anything I’ve talked about looks weird to you? \\nWhen you ask someone a question, will you \\nfirst present them with several related \\nproblems and their solutions? Or will you \\nfollow up with, “Let’s think step by step”? ', 'Develop a model that autonomously \\nlearns all the reasoning techniques we \\nhave introduced while addressing all the \\nlimitations we have identified \\n“The truth always turns out to be simpler than you thought.”  \\n— Richard P. Feynman ', '', '', 'THE END \\n\"The best way to predict the future is to invent it.\"  — Alan Kay  ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Open the PDF file\n",
    "pdf_file = PyPDF2.PdfReader(io.BytesIO(example_pdf))\n",
    "\n",
    "# Extract text from the PDF\n",
    "text = []\n",
    "for page_num in range(len(pdf_file.pages)):\n",
    "    page = pdf_file.pages[page_num]\n",
    "    text.append(page.extract_text())\n",
    "\n",
    "# Display the extracted text\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "Lecture 1: Introduction to LLM Reason\n",
      "Tokens used: 69\n",
      "Response:\n",
      "Lecture 1: AI Expectations and Applications\n",
      "Tokens used: 72\n",
      "Response:\n",
      "Lecture 1: Introduction to Artificial Intelligence\n",
      "\n",
      "\n",
      "Tokens used: 64\n",
      "Response:\n",
      "Lecture 1: Introduction to Machine Learning for\n",
      "Tokens used: 70\n",
      "Response:\n",
      "Lecture 1: Introduction to Missing Elements in\n",
      "Tokens used: 62\n",
      "Response:\n",
      "Lecture 1: Understanding Simplification in Legal\n",
      "Tokens used: 62\n",
      "Response:\n",
      "Lecture 1: Introduction to String Concaten\n",
      "Tokens used: 82\n",
      "Response:\n",
      "Lecture 1: Introduction to Machine Learning \n",
      "\n",
      "\n",
      "Tokens used: 89\n",
      "Response:\n",
      "Lecture 1: Introduction to Large Language Models\n",
      "Tokens used: 59\n",
      "Response:\n",
      "Lecture 1: Introduction to Large Language Models\n",
      "Tokens used: 98\n",
      "Response:\n",
      "Lecture 1: Introduction to Language Model Training\n",
      "Tokens used: 57\n",
      "Response:\n",
      "LECTURE 1: Introduction to Influential Personal\n",
      "Tokens used: 93\n",
      "Response:\n",
      "A: The last letter of \"Barack\"\n",
      "Tokens used: 176\n",
      "Response:\n",
      "Lecture 1: Introduction to String Manipulation\n",
      "Tokens used: 221\n",
      "Response:\n",
      "Lecture 1: Understanding String Concatenation\n",
      "Tokens used: 168\n",
      "Response:\n",
      "Lecture 1: Introduction to Program Induction\n",
      "Tokens used: 132\n",
      "Response:\n",
      "Lecture Transcript:\n",
      "\n",
      "Good day to all our L\n",
      "Tokens used: 296\n",
      "Response:\n",
      "Lecture 1: Introduction to Language Models and\n",
      "Tokens used: 96\n",
      "Response:\n",
      "Lecture 1: Introduction to Chain-of-Th\n",
      "Tokens used: 110\n",
      "Response:\n",
      "Lecture 1: Training with Intermediate Steps\n",
      "\n",
      "\n",
      "Tokens used: 107\n",
      "Response:\n",
      "Lecture 1: UNDERSTANDING THE FUNCTION\n",
      "Tokens used: 71\n",
      "Response:\n",
      "Lecture 1: Importance of Reasoning Strategies\n",
      "Tokens used: 53\n",
      "Response:\n",
      "Lecture 1: Introduction to Least-to-M\n",
      "Tokens used: 126\n",
      "Response:\n",
      "Lecture 1: Introduction to Legal Studies\n",
      "\n",
      "\n",
      "Tokens used: 38\n",
      "Response:\n",
      "Lecture 1: Introduction to Basic Arithmetic -\n",
      "Tokens used: 154\n",
      "Response:\n",
      "Lecture 1: Introduction to Compositional\n",
      "Tokens used: 63\n",
      "Response:\n",
      "Lecture 1: Introduction to Compositional\n",
      "Tokens used: 119\n",
      "Response:\n",
      "Lecture 1: The Practicality of Theory\n",
      "Tokens used: 61\n",
      "Response:\n",
      "Lecture 1: Understanding Transformers in Serial Problems\n",
      "Tokens used: 125\n",
      "Response:\n",
      "LECTURE 1: PRACTICAL IMPLICATION\n",
      "Tokens used: 98\n",
      "Response:\n",
      "Lecture 1: Introduction to Step-by-\n",
      "Tokens used: 58\n",
      "Response:\n",
      "Lecture 1: Introduction to Large Language Models\n",
      "Tokens used: 92\n",
      "Response:\n",
      "Lecture 1: Understanding Zero-Shot Learning\n",
      "Tokens used: 55\n",
      "Response:\n",
      "Lecture 1: Introduction to Large Language Models\n",
      "Tokens used: 107\n",
      "Response:\n",
      "Lecture 1: Introduction to LLM Studies\n",
      "Tokens used: 38\n",
      "Response:\n",
      "Lecture 1: Understanding the Role and Qual\n",
      "Tokens used: 111\n",
      "Response:\n",
      "Lecture Transcript:\n",
      "\n",
      "Good day, Class. Today\n",
      "Tokens used: 310\n",
      "Response:\n",
      "Lecture 1: An Introduction to Analogical\n",
      "Tokens used: 52\n",
      "Response:\n",
      "Lecture 1: Introduction to Analogical Reason\n",
      "Tokens used: 52\n",
      "Response:\n",
      "Title: Comparative Analysis: Analogical Reasoner vs\n",
      "Tokens used: 52\n",
      "Response:\n",
      "Lecture 1: Understanding Analogical Reasoning\n",
      "Tokens used: 65\n",
      "Response:\n",
      "Lecture 1: Triggering Step-by-\n",
      "Tokens used: 65\n",
      "Response:\n",
      "Lecture 1: Introduction to Chain-of-Th\n",
      "Tokens used: 89\n",
      "Response:\n",
      "Lecture 1: Introduction to Legal Logic and\n",
      "Tokens used: 134\n",
      "Response:\n",
      "Lecture 1: Probability and Statistics in Legal\n",
      "Tokens used: 123\n",
      "Response:\n",
      "Lecture 1: Understanding Basic Arithmetic Concepts through\n",
      "Tokens used: 175\n",
      "Response:\n",
      "Lecture 1: Understanding Pre-Trained L\n",
      "Tokens used: 109\n",
      "Response:\n",
      "Transcript 1: Introduction to Decoding Methods\n",
      "Tokens used: 50\n",
      "Response:\n",
      "Lecture 1: Introduction to LLM studies\n",
      "Tokens used: 48\n",
      "Response:\n",
      "Lecture 1: Understanding Legal Language Models (\n",
      "Tokens used: 76\n",
      "Response:\n",
      "Lecture 1: Introduction to LLM and\n",
      "Tokens used: 54\n",
      "Response:\n",
      "Lecture 1: Introduction to Computation and\n",
      "Tokens used: 52\n",
      "Response:\n",
      "Lecture 1: Introduction to Self-Cons\n",
      "Tokens used: 111\n",
      "Response:\n",
      "Lecture Transcript:\n",
      "\n",
      "Title: Comprehending Word\n",
      "Tokens used: 244\n",
      "Response:\n",
      "Lecture 1: Introduction to GSM8K\n",
      "Tokens used: 51\n",
      "Response:\n",
      "Lecture 1: The Importance of Consistency\n",
      "Tokens used: 47\n",
      "Response:\n",
      "[A1] Indeed, the procedure you described is\n",
      "Tokens used: 110\n",
      "Response:\n",
      "Lecture 1: Introduction to Universal Self-\n",
      "Tokens used: 144\n",
      "Response:\n",
      "Lecture 1: Comparing Coffee Consumption Glob\n",
      "Tokens used: 185\n",
      "Response:\n",
      "Lecture 1: Understanding the Limitations in\n",
      "Tokens used: 41\n",
      "Response:\n",
      "Lecture 1: Introduction to Language Models and\n",
      "Tokens used: 113\n",
      "Response:\n",
      "Lecture 1: The Impact of Irrelevant\n",
      "Tokens used: 175\n",
      "Response:\n",
      "Lecture 1: Understanding Basic Financial Transactions\n",
      "\n",
      "\n",
      "Tokens used: 131\n",
      "Response:\n",
      "Lecture 1: Understanding Financial Transactions and Bank\n",
      "Tokens used: 163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, page_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(text):\n\u001b[1;32m      4\u001b[0m     transcript \u001b[38;5;241m=\u001b[39m gpt\u001b[38;5;241m.\u001b[39mgenerate_response(user_prompt\u001b[38;5;241m=\u001b[39mpage_text)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtext_to_speech_mp3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranscript\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranscript_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.mp3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mtext_to_speech_mp3\u001b[0;34m(text, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtext_to_speech_mp3\u001b[39m(text, filename):\n\u001b[0;32m----> 2\u001b[0m     speech \u001b[38;5;241m=\u001b[39m \u001b[43mtext_to_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(speech\u001b[38;5;241m.\u001b[39mcontent)\n",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m, in \u001b[0;36mtext_to_speech\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtext_to_speech\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m     speech \u001b[38;5;241m=\u001b[39m \u001b[43mGPT\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspeech\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtts-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvoice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43monyx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m speech\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/openai/resources/audio/speech.py:96\u001b[0m, in \u001b[0;36mSpeech.create\u001b[0;34m(self, input, model, voice, response_format, speed, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03mGenerates audio from the input text.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     95\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/octet-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/audio/speech\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspeed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspeech_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSpeechCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_legacy_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHttpxBinaryResponseContent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1271\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1279\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1280\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m     )\n\u001b[0;32m-> 1283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/openai/_base_client.py:996\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    993\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 996\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1002\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpx/_client.py:928\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    927\u001b[0m     response\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 928\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpx/_client.py:922\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 922\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpx/_models.py:881\u001b[0m, in \u001b[0;36mResponse.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;124;03mRead and return the response content.\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpx/_models.py:897\u001b[0m, in \u001b[0;36mResponse.iter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    896\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_raw():\n\u001b[1;32m    898\u001b[0m         decoded \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(raw_bytes)\n\u001b[1;32m    899\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(decoded):\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpx/_models.py:951\u001b[0m, in \u001b[0;36mResponse.iter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    948\u001b[0m chunker \u001b[38;5;241m=\u001b[39m ByteChunker(chunk_size\u001b[38;5;241m=\u001b[39mchunk_size)\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request):\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m raw_stream_bytes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream:\n\u001b[1;32m    952\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(raw_stream_bytes)\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunker\u001b[38;5;241m.\u001b[39mdecode(raw_stream_bytes):\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpx/_client.py:153\u001b[0m, in \u001b[0;36mBoundSyncStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpx/_transports/default.py:127\u001b[0m, in \u001b[0;36mResponseStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpcore_stream:\n\u001b[1;32m    128\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:407\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:403\u001b[0m, in \u001b[0;36mPoolByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mIterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream:\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m part\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpcore/_sync/http11.py:342\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 342\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpcore/_sync/http11.py:334\u001b[0m, in \u001b[0;36mHTTP11ConnectionByteStream.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_body\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request, kwargs):\n\u001b[0;32m--> 334\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39m_receive_response_body(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpcore/_sync/http11.py:203\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    200\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mData):\n\u001b[1;32m    205\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event\u001b[38;5;241m.\u001b[39mdata)\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/ssl.py:1260\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1258\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1259\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/educator/lib/python3.9/ssl.py:1135\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1135\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gpt = GPT(system_prompt=\"create transcripts to teach the use given text for educational lectures for LLMs. \", max_tokens=10)\n",
    "\n",
    "for i, page_text in enumerate(text):\n",
    "    transcript = gpt.generate_response(user_prompt=page_text)\n",
    "    text_to_speech_mp3(transcript, f\"transcript_{i}.mp3\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement moviepy.editor (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for moviepy.editor\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy.editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Stitch the PDFs with the MP3 files\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmake_video\u001b[39m(slides, audio_file):\n\u001b[1;32m      5\u001b[0m     images \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "# Stitch the PDFs with the MP3 files\n",
    "import moviepy.editor as mp\n",
    "\n",
    "def make_video(slides, audio_file):\n",
    "    images = []\n",
    "    for slide in slides:\n",
    "        images.append(Image.open(slide))\n",
    "    clip = mp.ImageSequenceClip(images, fps=1)\n",
    "    audio = mp.AudioFileClip(audio_file)\n",
    "    video = clip.set_audio(audio)\n",
    "    video.write_videofile(f\"{audio_file}.mp4\", fps=1)\n",
    "\n",
    "make_video([f\"transcript_{i}.png\" for i in range(len(text))], \"hello_world.mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install mutagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mutagen\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "Installing collected packages: mutagen\n",
      "Successfully installed mutagen-1.47.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mutagen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (10.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (2.1.2)\n",
      "Requirement already satisfied: decorator<6.0,>=4.0.2 in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (from moviepy) (5.1.1)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (from moviepy) (2.37.0)\n",
      "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (from moviepy) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.25.0 in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: proglog<=1.0.0 in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: python-dotenv>=0.10 in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (from moviepy) (1.0.1)\n",
      "Requirement already satisfied: pillow<11.0,>=9.2.0 in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (from moviepy) (10.4.0)\n",
      "Requirement already satisfied: tqdm in /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages (from proglog<=1.0.0->moviepy) (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'editor' from 'moviepy' (/Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages/moviepy/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimageio\u001b[39;00m \n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m editor \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m \n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'editor' from 'moviepy' (/Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages/moviepy/__init__.py)"
     ]
    }
   ],
   "source": [
    "from mutagen.mp3 import MP3 \n",
    "from PIL import Image \n",
    "import imageio \n",
    "from moviepy import editor \n",
    "from pathlib import Path \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (226465151.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[7], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip show moviepy\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip show moviepy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: moviepy\n",
      "Version: 2.1.2\n",
      "Summary: Video editing with Python\n",
      "Home-page: \n",
      "Author: Zulko 2024\n",
      "Author-email: \n",
      "License: MIT License\n",
      "Location: /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages\n",
      "Requires: decorator, imageio, imageio_ffmpeg, numpy, pillow, proglog, python-dotenv\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show moviepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: moviepy 2.1.2\n",
      "Uninstalling moviepy-2.1.2:\n",
      "  Would remove:\n",
      "    /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages/moviepy-2.1.2.dist-info/*\n",
      "    /Users/arihantchoudhary/miniconda3/envs/educator/lib/python3.9/site-packages/moviepy/*\n",
      "Proceed (Y/n)? "
     ]
    }
   ],
   "source": [
    "pip uninstall moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "educator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
